---
title: "Storyboard - Loan Default Prediction in Nigeria"
author: "Hoang Huy, Li Ziyi, Hou Tao"
date-modified: "`r Sys.Date()`"
execute: 
  echo: true
  eval: true
  warning: false
format: 
  html:
    code-fold: false
    code-tools: false
linestretch: 2
editor: visual
---

![](images/intro1.jpg)

# Problem

Loan lending is one of the most important financial services. Loan default risk assessment is part of the loan lending process; it does impact the profitability of financial institutions when the loan receiver is unable to pay back on time. Customers' ability to pay back and willingness to pay back are essential considerations in loan lending.

# Challenges

Beside the difficulty and accuracy of customer loan default prediction in real words, more than often, imbalanced data collected are also have significant impact on customer loan default prediction, imbalanced data can resulted in poor performance with traditional predictive models and evaluation metrics that assume a balanced class distribution.

# Background

Loan lending offers substantial profits, but also carries the risk of customers failing to repay loans on time, known as loan default risk, which is a type of credit risk.

To manage uncertainty, lending institutions have established lending standards and created predictive models to better evaluate the likelihood of loan repayment through credit risk assessment of customers.

Over the past thirty years, loan default risk assessment has progressed from traditional credit scoring systems to data modeling utilizing data analytics and machine learning techniques.

# Motivation

This project aims to explore R technologies to develop reusable solutions (such as R-shiny application), to support users to perform data exploration, analysis, and prediction from set of customer variables to select the optimal variables to perform the customer loan default prediction.

# Data

The data that we are using, is from Data Science Nigeria Challenge #1: Loan Default Prediction.

There are two types of risk models in general:

-   1st new business risk, which would be used to assess the risk of application(s) associated with the first loan that he/she applies.

-   2nd repeat or behavior risk model, in which case the customer has been a client and applies for a repeat loan.

Overall, we can split the data into 2 main subsets of data: For Single Loans or Repeat Loans based on number of loans per customer in the data.

# Approach

To effectively predict the customer loan default, this study aims to provide following approaches to explore, analysis, mining factors are important to evaluate loan default.

-   Loan default factor exploration: it provides visualization on all or selected factors, to allow users to understand the trends of the variables, correlation of variables between each other.
-   Loan default factor mining: it provides deep dive analysis for customer further analysis the importance of loan default factors for prediction.
-   Loan default prediction: it provides interfaces for users to select variables, sampling methods, and predictive algorithms to model and analyze factors for customer loan default prediction.

# R-Shiny App

## Data Exploration

This is the first part of the R-Shiny application where users can perform Exploratory Data Analysis on this dataset, with the more common tools such as Distribution Analysis , Deviation Analysis and Scatterplot.

Distribution analysis is a statistical technique used to assess the symmetry and shape of a dataset. It involves examining the frequency distribution of a predictor variable to identify whether the data is normally distributed or skewed. If a variable is found to be highly skewed, this can impact the accuracy and reliability of statistical models, and may require data transformation or specialized modeling techniques.

Example:

![](images/image-400908432.png)Another tool can be employed is Deviation Analysis (box plot). Deviation analysis, often performed through box plots, is a graphical technique used to examine the relationship between a categorical predictor variable and a continuous variable. It provides a visual representation of the distribution of the continuous variable within each category of the predictor, and can reveal differences in variability or central tendency between groups. This can aid in identifying potential correlations between the two predictors and inform subsequent statistical analyses.

Example:

![](images/image-1949757529.png)

![](images/image-872201375.png)

Another type of analysis between 2 continuous variables is a scatterplot.

A scatterplot is a graphical tool used to visualize the relationship between two continuous variables. Each point on the plot represents a combination of values for the two variables, and the pattern of points can reveal the direction, strength, and form of the correlation between the variables. Scatterplots can aid in identifying potential associations between variables and provide insights into the nature of the relationship, which can inform subsequent analyses or hypotheses.

![](images/image-212117142.png)

## Deep Data Analysis

The second section of the R-shiny apps would provide users options to experiment with other analysis types such as Multi-collinearity test and Quasi Complete Separation to identify which variables should be include or exclude when building Classification model to predict credit frauds from our data.

### Multi-Collinearity Curse

Multicollinearity refers to the situation in which two or more predictor variables in a machine learning model are highly correlated with each other, making it difficult to identify the independent effects of each variable on the dependent variable.

In a classification model, multicollinearity can lead to unstable and unreliable estimates of the coefficients and make it difficult to interpret the model's results. It can also lead to overfitting and reduce the model's predictive accuracy. To address multicollinearity, one can exclude the highly correlated variables when building classification model

To determine whether multiple variables are in danger of compromising the model by this issue, we can utilize a correlation matrix.

A correlation matrix is a tool that can be used to identify multicollinearity by showing the pairwise correlations between each pair of predictor variables in the model. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation (when one variable increases, the other decreases) and 1 indicates a perfect positive correlation (when one variable increases, the other increases).

In the context of multicollinearity, a high correlation coefficient (close to 1 or -1) between two predictor variables indicates a strong linear relationship between them. This means that one variable can be predicted well by the other, and it becomes difficult to disentangle the effects of the two variables on the dependent variable. It's important to note that correlation doesn't imply causation, and that multicollinearity can also occur between three or more predictor variables, not just pairs.

![](images/prototype-4.png){fig-align="center"}

### Quasi Complete Separation

Another issue that our Shiny Apps can allow our users to explore, is the problem with quasi complete separation. Quasi-complete separation is a situation that can occur in classification when a predictor variable perfectly separates the outcome variable into distinct categories.

In other words, when a predictor variable has a perfect linear relationship with the outcome variable, the logistic regression model can perfectly predict which category the outcome variable belongs to based on the value of the predictor variable. This means that the estimated coefficient for the predictor variable becomes infinitely large.

Quasi-complete separation is particularly problematic in small or moderate-sized datasets because it can lead to overfitting and unreliable coefficient estimates. In addition, the model's performance can be sensitive to small changes in the data, which can make it difficult to interpret the results.

To address quasi-complete separation, there are several approaches that can be taken. One approach is to remove the problematic predictor variable or combine it with other variables to reduce its impact.

In some cases, quasi-complete separation may be a real phenomenon in the data and may require a different approach altogether. For example, if the data has a natural threshold or cutoff point, such as in medical diagnosis or credit scoring, the logistic regression model may need to be modified to account for this threshold. Overall, it's important to be aware of quasi-complete separation and to use appropriate methods to address it when it occurs.

One method of visual analytics to determine whether a predictor variable has the problem of quasi complete separation is by scatterplot. Quasi-complete separation can be visualized using a scatterplot, which can help to identify the problematic predictor variable and understand its relationship with the outcome variable.

![](images/image-573596474.png)

![](images/image-611142165.png)

In a barchar, the predictor variable is plotted on the x-axis and the outcome variable is plotted and stacked on the y-axis. When there is quasi-complete separation, we typically see that the data points fall into two distinct groups or clusters, with no overlap between the two groups.

## Loan Default Prediction

Upon analyzed variables identified for loan default prediction, next step is prediction. this study make use of Tidymodels library in R for prediction.

### Framework

The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.

1.  ***rsample*** : The rsample package provides functions to create different types of resamples and corresponding variables selected for prediction.

2.  ***parsnip***: The goal of parsnip is to provide a tidy, unified interface to models in loan default prediction.

3.  ***recipes***: Recipe to preprocessing data for loan default procession.

4.  ***yardstick***: Yardstick is a package to estimate how well models are working using tidy data principles.

![](images/prototype-6.png){fig-align="center"}

### Predictors

The UI provides two different loan prediction - New Loan and Repeat Loan. New loan is aim to provide prediction loan default for new customers based on various variables selected, while Repeat Loan is aim to provide prediction for existing customers based on various variables selected.

**Variables for New customers:**

1.  *bank_name_clients* : bank name
2.  *approval_duration_group* : approval duration grouping
3.  *age_at_loan_25th_pctile* : age at loan approval of 25th percentile
4.  *credit_rating* : borrower credict rating
5.  *termdays* : duration of loan
6.  *employment_status_risk* : employment status of borrower
7.  *level_of_education_risk* : education risk of borrower
8.  *referral* : referral
9.  *bank_account_type_recode* : bank account type
10. *loanamount_group* : loan amount grouping
11. *approval_duration* : approval duration
12. *loanamount* : loan amount
13. *totaldue* : total amount due of the loan
14. *Interestrate* : interest rate of loan (x100)
15. *age_at_loan* : age at the loan borrowed
16. *bank_account_type* : bank account type

**Variables for Existing customers:**

1.  *pct_ontime* : loan due one time percentile
2.  *total_ontime* : total no. of times loan due on time
3.  *max_active_of_loans* : maximum active loan borrowed
4.  *max_approval_duration* : maximum loan approval duration
5.  *bank_name_clients* : bank name of the loan borrowed
6.  *max_age_at_loan* : max age among all loan borrowed
7.  *avg_age_at_loan* : age age among all loan borrowed
8.  *employment_status* : employment status
9.  *bank_account_type* : bank account type
10. *total_referrals* : total referrals of borrowed
11. *avg_num_of_loans* : average number of loan borrowed
12. *total_num_of_loans* : total number of loan borrowed
13. *total_approval_duration* : total approval duration of all loans
14. *mean_approval_duration* : average approval duration of all loans
15. *max_interest_rate* : max interest rate
16. *mean_interest_rate* : averahe interest rate
17. *mean_referrals* : average referrals
18. *max_churn_flag* : maximum loan due on time
19. *mean_churn_flag* : average loan due on time
20. *loannumber* : loan number
21. *loanamount* : loan amount
22. *totaldue* : total amount due of the loan
23. *termdays* : loan duration

### Algorithms

It also can use different prediction algorithms to achieve better loan default prediction accuracy based on loan type and various variables selected.

1.  Nominal Logistic Regression

2.  Fit Stepwise -Boosted Tree

3.  Bootstrap Forest

The UI will enable interactive loan default prediction by selecting various variables and machine learning algorithms.
