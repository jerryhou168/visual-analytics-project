[
  {
    "objectID": "guide.html",
    "href": "guide.html",
    "title": "User Guide",
    "section": "",
    "text": "User Guide"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA-Project",
    "section": "",
    "text": "Loan Default Prediction Challenge\nLoan default prediction through data exploration, analysis and prediction using advanced R technologies\nGroup 5"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Problem\nLoan lending is one of the most important financial services. Loan default risk assessment is part of the loan lending process; it does impact the profitability of financial institutions when the loan receiver is unable to pay back on time. Customers’ ability to pay back and willingness to pay back are essential considerations in loan lending.\n\n\nChallenges\nBeside the difficulty and accuracy of customer loan default prediction in real words, more than often, imbalanced data collected are also have significant impact on customer loan default prediction, imbalanced data can resulted in poor performance with traditional predictive models and evaluation metrics that assume a balanced class distribution.\n\n\nSolutions\nIn this project, first, two types of loans 1) new and 2) repeating loans together with customer demographics and loan history are used in this study to analyze customers’ ability to pay and willingness to pay, and predictive models are provided to evaluate factors selected on compared customer loan default prediction."
  },
  {
    "objectID": "poster.html",
    "href": "poster.html",
    "title": "Poster",
    "section": "",
    "text": "library(ggplot2)\nlibrary(performance)\nlibrary(patchwork)\nlibrary(graphics)\nlibrary(ggthemes)\nlibrary(tidyverse)\n\n\nnewloan <- read_csv(\"C:/thomashoanghuy/visual-analytics-project/Rshiny/data/loan_data_v2/new_loans_cleaned.csv\", \n                    show_col_types = FALSE)\n\n\nhead(newloan)\n\n# A tibble: 6 × 21\n  row_id good_…¹ bank_…² appro…³ age_a…⁴ credi…⁵ termd…⁶ emplo…⁷ level…⁸ refer…⁹\n   <dbl> <chr>   <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <chr>   <chr>  \n1      1 Good    Standa… Low - … 36 - H…       1      30 Low     Low     No     \n2      2 Good    GT Bank Low - … 36 - H…       1      15 Low     Low     No     \n3      3 Good    First … 60.17 … 36 - H…       2      30 Low     Med     No     \n4      4 Good    GT Bank 61.13 … 36 - H…       2      15 Low     Med     No     \n5      5 Good    Diamon… 60.17 … 36 - H…       1      30 Low     Low     No     \n6      6 Good    GT Bank Low - … 28 - 32       3      30 Low     High    No     \n# … with 11 more variables: bank_account_type_recode <chr>,\n#   loanamount_group <chr>, approval_duration <dbl>, loanamount <dbl>,\n#   totaldue <dbl>, Interestrate <dbl>, age_at_loan <dbl>, longitude_gps <dbl>,\n#   latitude_gps <dbl>, bank_account_type <chr>, validation <chr>, and\n#   abbreviated variable names ¹​good_bad_flag, ²​bank_name_clients,\n#   ³​approval_duration_group, ⁴​age_at_loan_25th_pctile, ⁵​credit_rating,\n#   ⁶​termdays, ⁷​employment_status_risk, ⁸​level_of_education_risk, ⁹​referral\n\n\n\nggplot(data = newloan,\n       aes(x = approval_duration_group , fill = good_bad_flag)) +\ngeom_bar(bins = 20,\n                 color = \"lightblue\")+\n  theme_bw()"
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "",
    "text": "Loan lending offers substantial profits, but also carries the risk of customers failing to repay loans on time, known as loan default risk, which is a type of credit risk.\nTo manage uncertainty, lending institutions have established lending standards and created predictive models to better evaluate the likelihood of loan repayment through credit risk assessment of customers.\nOver the past thirty years, loan default risk assessment has progressed from traditional credit scoring systems to data modeling utilizing data analytics and machine learning techniques."
  },
  {
    "objectID": "proposal.html#data-exploration",
    "href": "proposal.html#data-exploration",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Data Exploration",
    "text": "Data Exploration\nThis is the first part of the R-Shiny application where users can perform Exploratory Data Analysis on this dataset, with the more common tools such as Distribution Analysis , Deviation Analysis and Scatterplot.\nDistribution analysis is a statistical technique used to assess the symmetry and shape of a dataset. It involves examining the frequency distribution of a predictor variable to identify whether the data is normally distributed or skewed. If a variable is found to be highly skewed, this can impact the accuracy and reliability of statistical models, and may require data transformation or specialized modeling techniques.\nExample:\nAnother tool can be employed is Deviation Analysis (box plot). Deviation analysis, often performed through box plots, is a graphical technique used to examine the relationship between a categorical predictor variable and a continuous variable. It provides a visual representation of the distribution of the continuous variable within each category of the predictor, and can reveal differences in variability or central tendency between groups. This can aid in identifying potential correlations between the two predictors and inform subsequent statistical analyses.\nExample:\n\n\nAnother type of analysis between 2 continuous variables is a scatterplot.\nA scatterplot is a graphical tool used to visualize the relationship between two continuous variables. Each point on the plot represents a combination of values for the two variables, and the pattern of points can reveal the direction, strength, and form of the correlation between the variables. Scatterplots can aid in identifying potential associations between variables and provide insights into the nature of the relationship, which can inform subsequent analyses or hypotheses."
  },
  {
    "objectID": "proposal.html#deep-data-analysis",
    "href": "proposal.html#deep-data-analysis",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Deep Data Analysis",
    "text": "Deep Data Analysis\nThe second section of the R-shiny apps would provide users options to experiment with other analysis types such as Multi-collinearity test and Quasi Complete Separation to identify which variables should be include or exclude when building Classification model to predict credit frauds from our data.\n\nMulti-Collinearity Curse\nMulticollinearity refers to the situation in which two or more predictor variables in a machine learning model are highly correlated with each other, making it difficult to identify the independent effects of each variable on the dependent variable.\nIn a classification model, multicollinearity can lead to unstable and unreliable estimates of the coefficients and make it difficult to interpret the model’s results. It can also lead to overfitting and reduce the model’s predictive accuracy. To address multicollinearity, one can exclude the highly correlated variables when building classification model\nTo determine whether multiple variables are in danger of compromising the model by this issue, we can utilize a correlation matrix.\nA correlation matrix is a tool that can be used to identify multicollinearity by showing the pairwise correlations between each pair of predictor variables in the model. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation (when one variable increases, the other decreases) and 1 indicates a perfect positive correlation (when one variable increases, the other increases).\nIn the context of multicollinearity, a high correlation coefficient (close to 1 or -1) between two predictor variables indicates a strong linear relationship between them. This means that one variable can be predicted well by the other, and it becomes difficult to disentangle the effects of the two variables on the dependent variable. It’s important to note that correlation doesn’t imply causation, and that multicollinearity can also occur between three or more predictor variables, not just pairs.\n\n\n\n\n\n\n\nQuasi Complete Separation\nAnother issue that our Shiny Apps can allow our users to explore, is the problem with quasi complete separation. Quasi-complete separation is a situation that can occur in classification when a predictor variable perfectly separates the outcome variable into distinct categories.\nIn other words, when a predictor variable has a perfect linear relationship with the outcome variable, the logistic regression model can perfectly predict which category the outcome variable belongs to based on the value of the predictor variable. This means that the estimated coefficient for the predictor variable becomes infinitely large.\nQuasi-complete separation is particularly problematic in small or moderate-sized datasets because it can lead to overfitting and unreliable coefficient estimates. In addition, the model’s performance can be sensitive to small changes in the data, which can make it difficult to interpret the results.\nTo address quasi-complete separation, there are several approaches that can be taken. One approach is to remove the problematic predictor variable or combine it with other variables to reduce its impact.\nIn some cases, quasi-complete separation may be a real phenomenon in the data and may require a different approach altogether. For example, if the data has a natural threshold or cutoff point, such as in medical diagnosis or credit scoring, the logistic regression model may need to be modified to account for this threshold. Overall, it’s important to be aware of quasi-complete separation and to use appropriate methods to address it when it occurs.\nOne method of visual analytics to determine whether a predictor variable has the problem of quasi complete separation is by scatterplot. Quasi-complete separation can be visualized using a scatterplot, which can help to identify the problematic predictor variable and understand its relationship with the outcome variable.\n\n\nIn a barchar, the predictor variable is plotted on the x-axis and the outcome variable is plotted and stacked on the y-axis. When there is quasi-complete separation, we typically see that the data points fall into two distinct groups or clusters, with no overlap between the two groups."
  },
  {
    "objectID": "proposal.html#loan-default-prediction",
    "href": "proposal.html#loan-default-prediction",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Loan Default Prediction",
    "text": "Loan Default Prediction\nUpon analyzed variables identified for loan default prediction, next step is prediction. this study make use of Tidymodels library in R for prediction.\n\nFramework\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\n\nrsample : The rsample package provides functions to create different types of resamples and corresponding variables selected for prediction.\nparsnip: The goal of parsnip is to provide a tidy, unified interface to models in loan default prediction.\nrecipes: Recipe to preprocessing data for loan default procession.\nyardstick: Yardstick is a package to estimate how well models are working using tidy data principles.\n\n\n\n\n\n\n\n\nPredictors\nThe UI provides two different loan prediction - New Loan and Repeat Loan. New loan is aim to provide prediction loan default for new customers based on various variables selected, while Repeat Loan is aim to provide prediction for existing customers based on various variables selected.\nVariables for New customers:\n\nbank_name_clients : bank name\napproval_duration_group : approval duration grouping\nage_at_loan_25th_pctile : age at loan approval of 25th percentile\ncredit_rating : borrower credict rating\ntermdays : duration of loan\nemployment_status_risk : employment status of borrower\nlevel_of_education_risk : education risk of borrower\nreferral : referral\nbank_account_type_recode : bank account type\nloanamount_group : loan amount grouping\napproval_duration : approval duration\nloanamount : loan amount\ntotaldue : total amount due of the loan\nInterestrate : interest rate of loan (x100)\nage_at_loan : age at the loan borrowed\nbank_account_type : bank account type\n\nVariables for Existing customers:\n\npct_ontime : loan due one time percentile\ntotal_ontime : total no. of times loan due on time\nmax_active_of_loans : maximum active loan borrowed\nmax_approval_duration : maximum loan approval duration\nbank_name_clients : bank name of the loan borrowed\nmax_age_at_loan : max age among all loan borrowed\navg_age_at_loan : age age among all loan borrowed\nemployment_status : employment status\nbank_account_type : bank account type\ntotal_referrals : total referrals of borrowed\navg_num_of_loans : average number of loan borrowed\ntotal_num_of_loans : total number of loan borrowed\ntotal_approval_duration : total approval duration of all loans\nmean_approval_duration : average approval duration of all loans\nmax_interest_rate : max interest rate\nmean_interest_rate : averahe interest rate\nmean_referrals : average referrals\nmax_churn_flag : maximum loan due on time\nmean_churn_flag : average loan due on time\nloannumber : loan number\nloanamount : loan amount\ntotaldue : total amount due of the loan\ntermdays : loan duration\n\n\n\nAlgorithms\nIt also can use different prediction algorithms to achieve better loan default prediction accuracy based on loan type and various variables selected.\n\nNominal Logistic Regression\nFit Stepwise -Boosted Tree\nBootstrap Forest\n\nThe UI will enable interactive loan default prediction by selecting various variables and machine learning algorithms."
  },
  {
    "objectID": "rshiny.html",
    "href": "rshiny.html",
    "title": "RSHINY APP",
    "section": "",
    "text": "RSHINY APP"
  },
  {
    "objectID": "story.html",
    "href": "story.html",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "",
    "text": "Loan lending offers substantial profits, but also carries the risk of customers failing to repay loans on time, known as loan default risk, which is a type of credit risk.\nTo manage uncertainty, lending institutions have established lending standards and created predictive models to better evaluate the likelihood of loan repayment through credit risk assessment of customers.\nOver the past thirty years, loan default risk assessment has progressed from traditional credit scoring systems to data modeling utilizing data analytics and machine learning techniques."
  },
  {
    "objectID": "story.html#data-exploration",
    "href": "story.html#data-exploration",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Data Exploration",
    "text": "Data Exploration\nThis is the first part of the R-Shiny application where users can perform Exploratory Data Analysis on this dataset, with the more common tools such as Distribution Analysis , Deviation Analysis and Scatterplot.\nDistribution analysis is a statistical technique used to assess the symmetry and shape of a dataset. It involves examining the frequency distribution of a predictor variable to identify whether the data is normally distributed or skewed. If a variable is found to be highly skewed, this can impact the accuracy and reliability of statistical models, and may require data transformation or specialized modeling techniques.\nExample:\n\n\n\n\n\nAnother tool can be employed is Deviation Analysis (box plot). Deviation analysis, often performed through box plots, is a graphical technique used to examine the relationship between a categorical predictor variable and a continuous variable. It provides a visual representation of the distribution of the continuous variable within each category of the predictor, and can reveal differences in variability or central tendency between groups. This can aid in identifying potential correlations between the two predictors and inform subsequent statistical analyses.\nExample:\n\n\n\n\n\nAnother type of analysis between 2 continuous variables is a scatterplot.\nA scatterplot is a graphical tool used to visualize the relationship between two continuous variables. Each point on the plot represents a combination of values for the two variables, and the pattern of points can reveal the direction, strength, and form of the correlation between the variables. Scatterplots can aid in identifying potential associations between variables and provide insights into the nature of the relationship, which can inform subsequent analyses or hypotheses."
  },
  {
    "objectID": "story.html#deep-data-analysis",
    "href": "story.html#deep-data-analysis",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Deep Data Analysis",
    "text": "Deep Data Analysis\nThe second section of the R-shiny apps would provide users options to experiment with other analysis types such as Multi-collinearity test and Quasi Complete Separation to identify which variables should be include or exclude when building Classification model to predict credit frauds from our data.\n\nMulti-Collinearity Curse\nMulticollinearity refers to the situation in which two or more predictor variables in a machine learning model are highly correlated with each other, making it difficult to identify the independent effects of each variable on the dependent variable.\nIn a classification model, multicollinearity can lead to unstable and unreliable estimates of the coefficients and make it difficult to interpret the model’s results. It can also lead to overfitting and reduce the model’s predictive accuracy. To address multicollinearity, one can exclude the highly correlated variables when building classification model\nTo determine whether multiple variables are in danger of compromising the model by this issue, we can utilize a correlation matrix.\nA correlation matrix is a tool that can be used to identify multicollinearity by showing the pairwise correlations between each pair of predictor variables in the model. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation (when one variable increases, the other decreases) and 1 indicates a perfect positive correlation (when one variable increases, the other increases).\nIn the context of multicollinearity, a high correlation coefficient (close to 1 or -1) between two predictor variables indicates a strong linear relationship between them. This means that one variable can be predicted well by the other, and it becomes difficult to disentangle the effects of the two variables on the dependent variable. It’s important to note that correlation doesn’t imply causation, and that multicollinearity can also occur between three or more predictor variables, not just pairs.\n\n\n\n\n\n\n\nQuasi Complete Separation\nAnother issue that our Shiny Apps can allow our users to explore, is the problem with quasi complete separation. Quasi-complete separation is a situation that can occur in classification when a predictor variable perfectly separates the outcome variable into distinct categories.\nIn other words, when a predictor variable has a perfect linear relationship with the outcome variable, the logistic regression model can perfectly predict which category the outcome variable belongs to based on the value of the predictor variable. This means that the estimated coefficient for the predictor variable becomes infinitely large.\nQuasi-complete separation is particularly problematic in small or moderate-sized datasets because it can lead to overfitting and unreliable coefficient estimates. In addition, the model’s performance can be sensitive to small changes in the data, which can make it difficult to interpret the results.\nTo address quasi-complete separation, there are several approaches that can be taken. One approach is to remove the problematic predictor variable or combine it with other variables to reduce its impact.\nIn some cases, quasi-complete separation may be a real phenomenon in the data and may require a different approach altogether. For example, if the data has a natural threshold or cutoff point, such as in medical diagnosis or credit scoring, the logistic regression model may need to be modified to account for this threshold. Overall, it’s important to be aware of quasi-complete separation and to use appropriate methods to address it when it occurs.\nOne method of visual analytics to determine whether a predictor variable has the problem of quasi complete separation is by scatterplot. Quasi-complete separation can be visualized using a scatterplot, which can help to identify the problematic predictor variable and understand its relationship with the outcome variable.\n\n\n\n\n\nIn a barchar, the predictor variable is plotted on the x-axis and the outcome variable is plotted and stacked on the y-axis. When there is quasi-complete separation, we typically see that the data points fall into two distinct groups or clusters, with no overlap between the two groups."
  },
  {
    "objectID": "story.html#loan-default-prediction",
    "href": "story.html#loan-default-prediction",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Loan Default Prediction",
    "text": "Loan Default Prediction\nUpon analyzed variables identified for loan default prediction, next step is prediction. this study make use of Tidymodels library in R for prediction.\n\nFramework\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\n\nrsample : The rsample package provides functions to create different types of resamples and corresponding variables selected for prediction.\nparsnip: The goal of parsnip is to provide a tidy, unified interface to models in loan default prediction.\nrecipes: Recipe to preprocessing data for loan default procession.\nyardstick: Yardstick is a package to estimate how well models are working using tidy data principles.\n\n\n\n\n\n\n\n\nPredictors\nThe UI provides two different loan prediction - New Loan and Repeat Loan. New loan is aim to provide prediction loan default for new customers based on various variables selected, while Repeat Loan is aim to provide prediction for existing customers based on various variables selected.\nVariables for New customers:\n\nbank_name_clients : bank name\napproval_duration_group : approval duration grouping\nage_at_loan_25th_pctile : age at loan approval of 25th percentile\ncredit_rating : borrower credict rating\ntermdays : duration of loan\nemployment_status_risk : employment status of borrower\nlevel_of_education_risk : education risk of borrower\nreferral : referral\nbank_account_type_recode : bank account type\nloanamount_group : loan amount grouping\napproval_duration : approval duration\nloanamount : loan amount\ntotaldue : total amount due of the loan\nInterestrate : interest rate of loan (x100)\nage_at_loan : age at the loan borrowed\nbank_account_type : bank account type\n\nVariables for Existing customers:\n\npct_ontime : loan due one time percentile\ntotal_ontime : total no. of times loan due on time\nmax_active_of_loans : maximum active loan borrowed\nmax_approval_duration : maximum loan approval duration\nbank_name_clients : bank name of the loan borrowed\nmax_age_at_loan : max age among all loan borrowed\navg_age_at_loan : age age among all loan borrowed\nemployment_status : employment status\nbank_account_type : bank account type\ntotal_referrals : total referrals of borrowed\navg_num_of_loans : average number of loan borrowed\ntotal_num_of_loans : total number of loan borrowed\ntotal_approval_duration : total approval duration of all loans\nmean_approval_duration : average approval duration of all loans\nmax_interest_rate : max interest rate\nmean_interest_rate : averahe interest rate\nmean_referrals : average referrals\nmax_churn_flag : maximum loan due on time\nmean_churn_flag : average loan due on time\nloannumber : loan number\nloanamount : loan amount\ntotaldue : total amount due of the loan\ntermdays : loan duration\n\n\n\nAlgorithms\nIt also can use different prediction algorithms to achieve better loan default prediction accuracy based on loan type and various variables selected.\n\nNominal Logistic Regression\nFit Stepwise -Boosted Tree\nBootstrap Forest\n\nThe UI will enable interactive loan default prediction by selecting various variables and machine learning algorithms."
  },
  {
    "objectID": "userguide.html",
    "href": "userguide.html",
    "title": "User Guide",
    "section": "",
    "text": "Univariate tab\nStep1: Select which datasets to be used (New Loans datasets or Repeated Loans dataset)\n\nStep 2: Next users have to choose which variables to be analyze under Univariate Analysis\n\nThe result bar chart will show you the distributions of the loans data as per the selected variable.\n\n\nBivariate tab\nStep 1: Select which datasets to be used (New Loans datasets or Repeated Loans dataset).\nStep 2: Choose variables X and Y to analyze if there is any concurrent relation between two variables.\n The plot on the right could be either a box-plot, scatter plot or Mosaic plot depends on whether variables chosen are continuous or categorical variables.\n\n\nCorrelation tab\nStep 1: Select which datasets to be used (New Loans datasets or Repeated Loans dataset).\nStep 2: Choose variables that you would like to analyze their correlations in between. Take note that at least two variables have to be chosen in order to display a proper correlation pairwise plot.\n\nA color legend would show up on the right. Green color signifies positive correlation and orange color represents negative correlation while the brightness translates the degree of correlation into visual representation.\nA significance test is also performed on all correlation between pairs of variables. A cross-mark would be displayed if the two paired variables produces a non-significant result.\n\n\nMulti Collinearity tab\nStep 1: Select which datasets to be used (New Loans datasets or Repeated Loans dataset).\nStep 2: Choose variables that you would like to conduct multicollinearity study with. Take note that at least two variables have to be chosen in order to display a proper multicollinearity study.\n\nA VIF value equal to 1 represents that variables chosen are not correlated. For VIF values fall within 1 to 5 (green area), it means variables chosen are moderately correlated. For VIF values fall within 5 to 10 (blue area), it means variables chosen are highly correlated.\nA table that comes along with multicollinearity would be produced at the bottom with values Variance Inflation Factor (VIF) as well as some of its associated statistical values like upper and lower confidence interval.\n\n\nQuasi Complete Seperation tab\nStep1: Select which datasets to be used (New Loans datasets or Repeated Loans dataset)\n\nStep 2: Next users have to choose which variables to be analyze to determine whether it violates the\n\nThe result will show you whether this particular variable would violate quasi complete separation issue. If it is, you will see one column / bar complete includes the majority (or total number) of one type of loan quality.\nFor example in the above situation, Variable “level of education risk”, for the high level of education risk ( for borrowers with lowest education levels), the majority of bad loans concentrated under this group, hence if user include this variable in the modelling, it may lead to overfitting and unreliable coefficient estimates."
  }
]