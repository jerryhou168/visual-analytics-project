[
  {
    "objectID": "guide.html",
    "href": "guide.html",
    "title": "User Guide",
    "section": "",
    "text": "User Guide"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA-Project",
    "section": "",
    "text": "Loan Default Prediction Challenge\nLoan default prediction through data exploration, analysis and prediction using advanced R technologies\nGroup 5"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction to Visual Analytics Project",
    "section": "",
    "text": "Problem\nLoan lending is one of the most important financial services. Loan default risk assessment is part of the loan lending process; it does impact the profitability of financial institutions when the loan receiver is unable to pay back on time. Customers’ ability to pay back and willingness to pay back are essential considerations in loan lending.\n\n\nChallenges\nBeside the difficulty and accuracy of customer loan default prediction in real words, more than often, imbalanced data collected are also have significant impact on customer loan default prediction, imbalanced data can resulted in poor performance with traditional predictive models and evaluation metrics that assume a balanced class distribution.\n\n\nSolutions\nIn this project, first, two types of loans 1) new and 2) repeating loans together with customer demographics and loan history are used in this study to analyze customers’ ability to pay and willingness to pay, and predictive models are provided to evaluate factors selected on compared customer loan default prediction."
  },
  {
    "objectID": "poster.html",
    "href": "poster.html",
    "title": "Poster",
    "section": "",
    "text": "Poster"
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "",
    "text": "Loan lending offers substantial profits, but also carries the risk of customers failing to repay loans on time, known as loan default risk, which is a type of credit risk.\nTo manage uncertainty, lending institutions have established lending standards and created predictive models to better evaluate the likelihood of loan repayment through credit risk assessment of customers.\nOver the past thirty years, loan default risk assessment has progressed from traditional credit scoring systems to data modeling utilizing data analytics and machine learning techniques."
  },
  {
    "objectID": "proposal.html#exploratory-data-analysis-eda",
    "href": "proposal.html#exploratory-data-analysis-eda",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\nThis is the first part of the R-Shiny application where users can perform Exploratory Data Analysis on this dataset, with the more common tools such as Distribution Analysis , Deviation Analysis and Scatterplot.\nDistribution analysis is a statistical technique used to assess the symmetry and shape of a dataset. It involves examining the frequency distribution of a predictor variable to identify whether the data is normally distributed or skewed. If a variable is found to be highly skewed, this can impact the accuracy and reliability of statistical models, and may require data transformation or specialized modeling techniques.\nExample:\n\n\n\n\n\nAnother tool can be employed is Deviation Analysis (box plot). Deviation analysis, often performed through box plots, is a graphical technique used to examine the relationship between a categorical predictor variable and a continuous variable. It provides a visual representation of the distribution of the continuous variable within each category of the predictor, and can reveal differences in variability or central tendency between groups. This can aid in identifying potential correlations between the two predictors and inform subsequent statistical analyses.\nExample:\n\n\n\n\n\nAnother type of analysis between 2 continuous variables is a scatterplot.\nA scatterplot is a graphical tool used to visualize the relationship between two continuous variables. Each point on the plot represents a combination of values for the two variables, and the pattern of points can reveal the direction, strength, and form of the correlation between the variables. Scatterplots can aid in identifying potential associations between variables and provide insights into the nature of the relationship, which can inform subsequent analyses or hypotheses."
  },
  {
    "objectID": "proposal.html#prototype-of-first-page",
    "href": "proposal.html#prototype-of-first-page",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "PROTOTYPE OF FIRST PAGE",
    "text": "PROTOTYPE OF FIRST PAGE\n\n\n\nPrototype slide 1"
  },
  {
    "objectID": "proposal.html#multi--collinearity-curse",
    "href": "proposal.html#multi--collinearity-curse",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Multi- Collinearity Curse",
    "text": "Multi- Collinearity Curse\nMulticollinearity refers to the situation in which two or more predictor variables in a machine learning model are highly correlated with each other, making it difficult to identify the independent effects of each variable on the dependent variable.\nIn a classification model, multicollinearity can lead to unstable and unreliable estimates of the coefficients and make it difficult to interpret the model’s results. It can also lead to overfitting and reduce the model’s predictive accuracy. To address multicollinearity, one can exclude the highly correlated variables when building classification model\nTo determine whether multiple variables are in danger of compromising the model by this issue, we can utilize a correlation matrix.\nA correlation matrix is a tool that can be used to identify multicollinearity by showing the pairwise correlations between each pair of predictor variables in the model. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation (when one variable increases, the other decreases) and 1 indicates a perfect positive correlation (when one variable increases, the other increases).\nIn the context of multicollinearity, a high correlation coefficient (close to 1 or -1) between two predictor variables indicates a strong linear relationship between them. This means that one variable can be predicted well by the other, and it becomes difficult to disentangle the effects of the two variables on the dependent variable. It’s important to note that correlation doesn’t imply causation, and that multicollinearity can also occur between three or more predictor variables, not just pairs."
  },
  {
    "objectID": "proposal.html#section",
    "href": "proposal.html#section",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "",
    "text": "Quasi Complete Separation\nAnother issue that our Shiny Apps can allow our users to explore, is the problem with quasi complete separation. Quasi-complete separation is a situation that can occur in classification when a predictor variable perfectly separates the outcome variable into distinct categories.\nIn other words, when a predictor variable has a perfect linear relationship with the outcome variable, the logistic regression model can perfectly predict which category the outcome variable belongs to based on the value of the predictor variable. This means that the estimated coefficient for the predictor variable becomes infinitely large.\nQuasi-complete separation is particularly problematic in small or moderate-sized datasets because it can lead to overfitting and unreliable coefficient estimates. In addition, the model’s performance can be sensitive to small changes in the data, which can make it difficult to interpret the results.\nTo address quasi-complete separation, there are several approaches that can be taken. One approach is to remove the problematic predictor variable or combine it with other variables to reduce its impact.\nIn some cases, quasi-complete separation may be a real phenomenon in the data and may require a different approach altogether. For example, if the data has a natural threshold or cutoff point, such as in medical diagnosis or credit scoring, the logistic regression model may need to be modified to account for this threshold. Overall, it’s important to be aware of quasi-complete separation and to use appropriate methods to address it when it occurs.\nOne method of visual analytics to determine whether a predictor variable has the problem of quasi complete separation is by scatterplot. Quasi-complete separation can be visualized using a scatterplot, which can help to identify the problematic predictor variable and understand its relationship with the outcome variable.\nIn a scatterplot, the predictor variable is plotted on the x-axis and the outcome variable is plotted on the y-axis. When there is quasi-complete separation, we typically see that the data points fall into two distinct groups or clusters, with no overlap between the two groups."
  },
  {
    "objectID": "proposal.html#loan-default-prediction-using-classification-algorithms",
    "href": "proposal.html#loan-default-prediction-using-classification-algorithms",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Loan default prediction using classification algorithms",
    "text": "Loan default prediction using classification algorithms\nUpon analyzed variables identified for loan default prediction, next step is prediction. this study make use of Tidymodels library in R for prediction.\n\nTidymodels\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\nrsample library\nThe rsample package provides functions to create different types of resamples and corresponding variables selected for prediction.\nparsnip library\nThe goal of parsnip is to provide a tidy, unified interface to models in loan default prediction.\nrecipes library\nRecipe to preprocessing data for loan default procession.\nyardstick library\nYardstick is a package to estimate how well models are working using tidy data principles.\n\n\n\nPrediction\n\n\n\n\nLoan Type\nThe UI below provides two different loan prediction - New Loan and Repeat Loan. New loan is aim to provide prediction loan default for new customers based on various variables selected, while Repeat Loan is aim to provide prediction for existing customers based on various variables selected.\nVariables for New customers:\n\nbank_name_clients : bank name\napproval_duration_group : approval duration grouping\nage_at_loan_25th_pctile : age at loan approval of 25th percentile\ncredit_rating : borrower credict rating\ntermdays : duration of loan\nemployment_status_risk : employment status of borrower\nlevel_of_education_risk : education risk of borrower\nreferral : referral\nbank_account_type_recode : bank account type\nloanamount_group : loan amount grouping\napproval_duration : approval duration\nloanamount : loan amount\ntotaldue : total amount due of the loan\nInterestrate : interest rate of loan (x100)\nage_at_loan : age at the loan borrowed\nlongitude_gps : customer loan\nlatitude_gps : customer loan\nbank_account_type : bank account type\n\nVariables for Existing customers:\n\npct_ontime : loan due one time percentile\ntotal_ontime : total no. of times loan due on time\nmax_active_of_loans : maximum active loan borrowed\nmax_approval_duration : maximum loan approval duration\nbank_name_clients : bank name of the loan borrowed\nmax_age_at_loan : max age among all loan borrowed\navg_age_at_loan : age age among all loan borrowed\nemployment_status : employment status\nbank_account_type : bank account type\ntotal_referrals : total referrals of borrowed\navg_num_of_loans : average number of loan borrowed\ntotal_num_of_loans : total number of loan borrowed\ntotal_approval_duration : total approval duration of all loans\nmean_approval_duration : average approval duration of all loans\nmax_interest_rate : max interest rate\nmean_interest_rate : averahe interest rate\nmean_referrals : average referrals\nmax_churn_flag : maximum loan due on time\nmean_churn_flag : average loan due on time\nloannumber : loan number\nloanamount : loan amount\ntotaldue : total amount due of the loan\ntermdays : loan duration\nlongitude : customer location\n*latitude** : customer location\n\n\n\nAlgorithms\nIt also can use different prediction algorithms to achieve better loan default prediction accuracy based on loan type and various variables selected.\n\nNominal Logistic Regression\nFit Stepwise -Boosted Tree\nBootstrap Forest\n\n\n\nData Sampling\nThis study also provide sampling method to overcome data inbalance issues. following sampling methods are provided:\n\nOversampling\nTomek Sampling\nSMOTE plus Tomek Sampling\n\nThe UI will enable interactive loan default prediction by selecting various variables, algorithms and sampling methods."
  },
  {
    "objectID": "rshiny.html",
    "href": "rshiny.html",
    "title": "RSHINY APP",
    "section": "",
    "text": "RSHINY APP"
  },
  {
    "objectID": "story.html",
    "href": "story.html",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "",
    "text": "Loan lending offers substantial profits, but also carries the risk of customers failing to repay loans on time, known as loan default risk, which is a type of credit risk.\nTo manage uncertainty, lending institutions have established lending standards and created predictive models to better evaluate the likelihood of loan repayment through credit risk assessment of customers.\nOver the past thirty years, loan default risk assessment has progressed from traditional credit scoring systems to data modeling utilizing data analytics and machine learning techniques."
  },
  {
    "objectID": "story.html#exploratory-data-analysis-eda",
    "href": "story.html#exploratory-data-analysis-eda",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\nThis is the first part of the R-Shiny application where users can perform Exploratory Data Analysis on this dataset, with the more common tools such as Distribution Analysis , Deviation Analysis and Scatterplot.\nDistribution analysis is a statistical technique used to assess the symmetry and shape of a dataset. It involves examining the frequency distribution of a predictor variable to identify whether the data is normally distributed or skewed. If a variable is found to be highly skewed, this can impact the accuracy and reliability of statistical models, and may require data transformation or specialized modeling techniques.\nExample:\n\n\n\n\n\nAnother tool can be employed is Deviation Analysis (box plot). Deviation analysis, often performed through box plots, is a graphical technique used to examine the relationship between a categorical predictor variable and a continuous variable. It provides a visual representation of the distribution of the continuous variable within each category of the predictor, and can reveal differences in variability or central tendency between groups. This can aid in identifying potential correlations between the two predictors and inform subsequent statistical analyses.\nExample:\n\n\n\n\n\nAnother type of analysis between 2 continuous variables is a scatterplot.\nA scatterplot is a graphical tool used to visualize the relationship between two continuous variables. Each point on the plot represents a combination of values for the two variables, and the pattern of points can reveal the direction, strength, and form of the correlation between the variables. Scatterplots can aid in identifying potential associations between variables and provide insights into the nature of the relationship, which can inform subsequent analyses or hypotheses."
  },
  {
    "objectID": "story.html#prototype-of-first-page",
    "href": "story.html#prototype-of-first-page",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "PROTOTYPE OF FIRST PAGE",
    "text": "PROTOTYPE OF FIRST PAGE\n\n\n\nPrototype slide 1"
  },
  {
    "objectID": "story.html#multi--collinearity-curse",
    "href": "story.html#multi--collinearity-curse",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Multi- Collinearity Curse",
    "text": "Multi- Collinearity Curse\nMulticollinearity refers to the situation in which two or more predictor variables in a machine learning model are highly correlated with each other, making it difficult to identify the independent effects of each variable on the dependent variable.\nIn a classification model, multicollinearity can lead to unstable and unreliable estimates of the coefficients and make it difficult to interpret the model’s results. It can also lead to overfitting and reduce the model’s predictive accuracy. To address multicollinearity, one can exclude the highly correlated variables when building classification model\nTo determine whether multiple variables are in danger of compromising the model by this issue, we can utilize a correlation matrix.\nA correlation matrix is a tool that can be used to identify multicollinearity by showing the pairwise correlations between each pair of predictor variables in the model. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation (when one variable increases, the other decreases) and 1 indicates a perfect positive correlation (when one variable increases, the other increases).\nIn the context of multicollinearity, a high correlation coefficient (close to 1 or -1) between two predictor variables indicates a strong linear relationship between them. This means that one variable can be predicted well by the other, and it becomes difficult to disentangle the effects of the two variables on the dependent variable. It’s important to note that correlation doesn’t imply causation, and that multicollinearity can also occur between three or more predictor variables, not just pairs."
  },
  {
    "objectID": "story.html#quasi-complete-separation",
    "href": "story.html#quasi-complete-separation",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Quasi Complete Separation",
    "text": "Quasi Complete Separation\nAnother issue that our Shiny Apps can allow our users to explore, is the problem with quasi complete separation. Quasi-complete separation is a situation that can occur in classification when a predictor variable perfectly separates the outcome variable into distinct categories.\nIn other words, when a predictor variable has a perfect linear relationship with the outcome variable, the logistic regression model can perfectly predict which category the outcome variable belongs to based on the value of the predictor variable. This means that the estimated coefficient for the predictor variable becomes infinitely large.\nQuasi-complete separation is particularly problematic in small or moderate-sized datasets because it can lead to overfitting and unreliable coefficient estimates. In addition, the model’s performance can be sensitive to small changes in the data, which can make it difficult to interpret the results.\nTo address quasi-complete separation, there are several approaches that can be taken. One approach is to remove the problematic predictor variable or combine it with other variables to reduce its impact.\nIn some cases, quasi-complete separation may be a real phenomenon in the data and may require a different approach altogether. For example, if the data has a natural threshold or cutoff point, such as in medical diagnosis or credit scoring, the logistic regression model may need to be modified to account for this threshold. Overall, it’s important to be aware of quasi-complete separation and to use appropriate methods to address it when it occurs.\nOne method of visual analytics to determine whether a predictor variable has the problem of quasi complete separation is by scatterplot. Quasi-complete separation can be visualized using a scatterplot, which can help to identify the problematic predictor variable and understand its relationship with the outcome variable.\nIn a scatterplot, the predictor variable is plotted on the x-axis and the outcome variable is plotted on the y-axis. When there is quasi-complete separation, we typically see that the data points fall into two distinct groups or clusters, with no overlap between the two groups."
  },
  {
    "objectID": "story.html#loan-default-prediction-using-classification-algorithms",
    "href": "story.html#loan-default-prediction-using-classification-algorithms",
    "title": "Storyboard - Loan Default Prediction in Nigeria",
    "section": "Loan default prediction using classification algorithms",
    "text": "Loan default prediction using classification algorithms\nUpon analyzed variables identified for loan default prediction, next step is prediction. this study make use of Tidymodels library in R for prediction.\n\nTidymodels\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\nrsample library\nThe rsample package provides functions to create different types of resamples and corresponding variables selected for prediction.\nparsnip library\nThe goal of parsnip is to provide a tidy, unified interface to models in loan default prediction.\nrecipes library\nRecipe to preprocessing data for loan default procession.\nyardstick library\nYardstick is a package to estimate how well models are working using tidy data principles.\n\n\n\nPrediction\n\n\n\n\nLoan Type\nThe UI below provides two different loan prediction - New Loan and Repeat Loan. New loan is aim to provide prediction loan default for new customers based on various variables selected, while Repeat Loan is aim to provide prediction for existing customers based on various variables selected.\nVariables for New customers:\n\nbank_name_clients : bank name\napproval_duration_group : approval duration grouping\nage_at_loan_25th_pctile : age at loan approval of 25th percentile\ncredit_rating : borrower credict rating\ntermdays : duration of loan\nemployment_status_risk : employment status of borrower\nlevel_of_education_risk : education risk of borrower\nreferral : referral\nbank_account_type_recode : bank account type\nloanamount_group : loan amount grouping\napproval_duration : approval duration\nloanamount : loan amount\ntotaldue : total amount due of the loan\nInterestrate : interest rate of loan (x100)\nage_at_loan : age at the loan borrowed\nlongitude_gps : customer loan\nlatitude_gps : customer loan\nbank_account_type : bank account type\n\nVariables for Existing customers:\n\npct_ontime : loan due one time percentile\ntotal_ontime : total no. of times loan due on time\nmax_active_of_loans : maximum active loan borrowed\nmax_approval_duration : maximum loan approval duration\nbank_name_clients : bank name of the loan borrowed\nmax_age_at_loan : max age among all loan borrowed\navg_age_at_loan : age age among all loan borrowed\nemployment_status : employment status\nbank_account_type : bank account type\ntotal_referrals : total referrals of borrowed\navg_num_of_loans : average number of loan borrowed\ntotal_num_of_loans : total number of loan borrowed\ntotal_approval_duration : total approval duration of all loans\nmean_approval_duration : average approval duration of all loans\nmax_interest_rate : max interest rate\nmean_interest_rate : averahe interest rate\nmean_referrals : average referrals\nmax_churn_flag : maximum loan due on time\nmean_churn_flag : average loan due on time\nloannumber : loan number\nloanamount : loan amount\ntotaldue : total amount due of the loan\ntermdays : loan duration\nlongitude : customer location\n*latitude** : customer location\n\n\n\nAlgorithms\nIt also can use different prediction algorithms to achieve better loan default prediction accuracy based on loan type and various variables selected.\n\nNominal Logistic Regression\nFit Stepwise -Boosted Tree\nBootstrap Forest\n\n\n\nData Sampling\nThis study also provide sampling method to overcome data inbalance issues. following sampling methods are provided:\n\nOversampling\nTomek Sampling\nSMOTE plus Tomek Sampling\n\nThe UI will enable interactive loan default prediction by selecting various variables, algorithms and sampling methods."
  }
]